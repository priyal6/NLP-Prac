# -*- coding: utf-8 -*-
"""retrieve&rerank.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WoyK1oKoZntVtQ5VeUwoNv0eRx7A4db3
"""

!pip install -U sentence-transformers rank_bm25

import gzip
import json
import os

import torch

from sentence_transformers import CrossEncoder, SentenceTransformer, util

if not torch.cuda.is_available():
  print("Warning: No GPU found. Please add GPU to your notebook")

bi_encoder = SentenceTransformer("multi-qa-MiniLM-L6-cos-v1")
bi_encoder.max_seq_length = 256
top_k = 32 #no of item we retrieve

cross_encoder = CrossEncoder("cross-encoder/ms-marco-MiniLM-L6-v2")

wikipedia_filepath = "simplewiki-2020-11-01.jsonl.gz"

if not os.path.exists(wikipedia_filepath):
  util.http_get("http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz", wikipedia_filepath)

passages= []
with gzip.open(wikipedia_filepath, "rt", encoding = "utf8") as fIn:
  for line in fIn:
    data = json.loads(line.strip())

    passages.append(data["paragraphs"][0])

print("Passages:", len(passages))

corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)

def search(query):
  print("Input question:", query)


  question_embedding = bi_encoder.encode(query, convert_to_tensor=True)
  question_embedding = question_embedding.cuda()
  hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)
  hits = hits[0]

  cross_inp = [[query, passages[hit["corpus_id"]]] for hit in hits]
  cross_scores = cross_encoder.predict(cross_inp)

  for idx in range(len(cross_scores)):
    hits[idx]["cross-score"] = cross_scores[idx]


  print("Top-3 Bi-Encoder Retrieval hits")
  hits = sorted(hits, key= lambda x: x["score"], reverse=True)
  for hit in hits[0:3]:
    print("\t{:.3f}\t{}".format(hit["score"], passages[hit["corpus_id"]].replace("\n", " ")))


  print("Top-3 Cross-Encoder Re-Ranker hits")
  hits = sorted(hits, key= lambda x: x["cross-score"], reverse=True)
  for hit in hits[0:3]:
     print("\t{:.3f}\t{}".format(hit["cross-score"], passages[hit["corpus_id"]].replace("\n", " ")))

search(query="What is the capital of the United States?")

search(query="How many people live in Toronto?")

search(query="What is reinforcement learning?")

search(query = "What is sequence level tokenisation in comparasion to RL?")